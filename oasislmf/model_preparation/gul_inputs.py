__all__ = [
    'generate_gul_input_items',
    'get_gul_input_items',
    'write_coverages_file',
    'write_gulsummaryxref_file',
    'write_gul_input_files',
    'write_items_file'
]

import os
import multiprocessing
import sys

from itertools import (
    chain,
    product,
)
from future.utils import viewkeys

import pandas as pd

from ..utils.concurrency import (
    multithread,
    Task,
)
from ..utils.data import get_dataframe
from ..utils.exceptions import OasisException
from ..utils.log import oasis_log
from ..utils.metadata import OED_COVERAGE_TYPES
from ..utils.defaults import get_default_exposure_profile
from .il_inputs import unified_fm_profile_by_level_and_term_group


@oasis_log
def generate_gul_input_items(
    exposure_df,
    keys_df,
    exposure_profile=get_default_exposure_profile()
):
    """
    Generates GUL input items.

    :param exposure_df: OED source exposure
    :type exposure_df: pandas.DataFrame

    :param keys_df: Keys data generated by a model lookup or some other source
    :type keys_df: pandas.DataFrame

    :param exposure_profile: OED source exposure profile
    :type exposure_profile: dict
    """
    exppf = exposure_profile

    ufp = unified_fm_profile_by_level_and_term_group(profiles=(exppf,))

    if not ufp:
        raise OasisException(
            'Source exposure profile is possibly missing FM term information: '
            'FM term definitions for TIV, limit, deductible, attachment and/or share.'
        )

    fm_levels = tuple(ufp.keys())

    try:
        for df in [exposure_df, keys_df]:
            if not df.columns.contains('index'):
                df['index'] = pd.Series(data=range(len(df)))

        if not str(exposure_df['locnumber'].dtype).startswith('int'):
            exposure_df['locnumber'] = exposure_df['locnumber'].astype(int)

        if not str(keys_df['locid'].dtype).startswith('int'):
            keys_df['locid'] = keys_df['locid'].astype(int)

        merged_df = pd.merge(exposure_df, keys_df, left_on='locnumber', right_on='locid').drop_duplicates()
        merged_df['index'] = pd.Series(data=range(len(merged_df)), dtype=object)

        cov_level_id = fm_levels[0]

        cov_tivs = tuple(t for t in [ufp[cov_level_id][gid].get('tiv') for gid in ufp[cov_level_id]] if t)

        if not cov_tivs:
            raise OasisException('No coverage fields found in the source exposure profile - please check the source exposure (loc) profile')

        fm_terms = {
            tiv_tgid: {
                term_type: (
                    ufp[cov_level_id][tiv_tgid][term_type]['ProfileElementName'].lower() if ufp[cov_level_id][tiv_tgid].get(term_type) else None
                ) for term_type in ('deductible', 'deductiblemin', 'deductiblemax', 'limit',)
            } for tiv_tgid in ufp[cov_level_id]
        }

        group_id = 0
        prev_it_loc_id = -1
        item_id = 0
        zero_tiv_items = 0

        def positive_tiv_coverages(it):
            return [t for t in cov_tivs if it.get(t['ProfileElementName'].lower()) and it[t['ProfileElementName'].lower()] > 0 and t['CoverageTypeID'] == it['coveragetypeid']] or [0]

        for it, ptiv in chain((it, ptiv) for _, it in merged_df.iterrows() for it, ptiv in product([it], positive_tiv_coverages(it))):
            if ptiv == 0:
                zero_tiv_items += 1
                continue

            item_id += 1
            if it['locnumber'] != prev_it_loc_id:
                group_id += 1

            tiv_elm = ptiv['ProfileElementName'].lower()
            tiv = it[tiv_elm]
            tiv_tgid = ptiv['FMTermGroupID']

            yield {
                'item_id': item_id,
                'loc_id': it['locnumber'],
                'acc_id': it['accnumber'],
                'peril_id': it['perilid'],
                'coverage_type_id': it['coveragetypeid'],
                'coverage_id': item_id,
                'is_bi_coverage': it['coveragetypeid'] == OED_COVERAGE_TYPES['bi']['id'],
                'tiv_elm': tiv_elm,
                'tiv': tiv,
                'tiv_tgid': tiv_tgid,
                'deductible': it.get(fm_terms[tiv_tgid].get('deductible') or None) or 0,
                'deductible_min': it.get(fm_terms[tiv_tgid].get('deductiblemin') or None) or 0,
                'deductible_max': it.get(fm_terms[tiv_tgid].get('deductiblemax') or None) or 0,
                'limit': it.get(fm_terms[tiv_tgid].get('limit') or None) or 0,
                'areaperil_id': it['areaperilid'],
                'vulnerability_id': it['vulnerabilityid'],
                'group_id': group_id,
                'summary_id': 1,
                'summaryset_id': 1
            }
            prev_it_loc_id = it['locnumber']

    except (AttributeError, KeyError, IndexError, TypeError, ValueError) as e:
        raise OasisException(e)
    else:
        if zero_tiv_items == len(merged_df):
            raise OasisException('All source exposure items have zero TIVs - please check the source exposure (loc.) file')


@oasis_log
def get_gul_input_items(exposure_fp, keys_fp, exposure_profile=get_default_exposure_profile()):
    """
    Loads GUL input items generated by ``generate_gul_input_items`` as a
    Pandas dataframe

    :param exposure_fp: OED source exposure file path
    :type exposure_fp: str

    :param keys_file_path: Keys file path
    :type keys_file_path: str

    :param exposure_profile: OED source exposure profile
    :type exposure_profile: dict
    """
    exppf = exposure_profile

    try:
        exposure_df = get_dataframe(src_fp=exposure_fp, empty_data_error_msg='No source exposure found in the source exposure (loc.) file')
        keys_df = get_dataframe(src_fp=keys_fp, empty_data_error_msg='No keys found in the keys file')

        gul_inputs_df = pd.DataFrame(data=[it for it in generate_gul_input_items(exposure_df, keys_df, exposure_profile=exposure_profile)], dtype=object)
        gul_inputs_df['index'] = pd.Series(data=gul_inputs_df.index, dtype=int)

        for col in gul_inputs_df.columns:
            if col == 'peril_id':
                gul_inputs_df[col] = gul_inputs_df[col].astype(object)
            elif col.endswith('id'):
                gul_inputs_df[col] = gul_inputs_df[col].astype(int)
            elif col == 'tiv':
                gul_inputs_df[col] = gul_inputs_df[col].astype(float)
    except (IOError, MemoryError, OasisException, OSError, TypeError, ValueError) as e:
        raise OasisException(e)

    return gul_inputs_df, exposure_df


def write_items_file(gul_inputs_df, items_fp):
    """
    Writes an items file.
    """
    try:
        gul_inputs_df.to_csv(
            columns=['item_id', 'coverage_id', 'areaperil_id', 'vulnerability_id', 'group_id'],
            path_or_buf=items_fp,
            encoding='utf-8',
            chunksize=1000,
            index=False
        )
    except (IOError, OSError) as e:
        raise OasisException(e)

    return items_fp


def write_coverages_file(gul_inputs_df, coverages_fp):
    """
    Writes a coverages file.
    """
    try:
        gul_inputs_df.to_csv(
            columns=['coverage_id', 'tiv'],
            path_or_buf=coverages_fp,
            encoding='utf-8',
            chunksize=1000,
            index=False
        )
    except (IOError, OSError) as e:
        raise OasisException(e)

    return coverages_fp


def write_gulsummaryxref_file(gul_inputs_df, gulsummaryxref_fp):
    """
    Writes a gulsummaryxref file.
    """
    try:
        gul_inputs_df.to_csv(
            columns=['coverage_id', 'summary_id', 'summaryset_id'],
            path_or_buf=gulsummaryxref_fp,
            encoding='utf-8',
            chunksize=1000,
            index=False
        )
    except (IOError, OSError) as e:
        raise OasisException(e)

    return gulsummaryxref_fp


@oasis_log
def write_gul_input_files(
    exposure_fp,
    keys_fp,
    target_dir,
    exposure_profile=get_default_exposure_profile(),
    oasis_files_prefixes={
        'items': 'items',
        'coverages': 'coverages',
        'gulsummaryxref': 'gulsummaryxref'
    }
):
    """
    Writes the standard Oasis GUL input files, namely::

        items.csv
        coverages.csv
        gulsummaryxref.csv
    """
    gul_inputs_df, exposure_df = get_gul_input_items(exposure_fp, keys_fp)

    gul_input_files = {
        k: os.path.join(target_dir, '{}.csv'.format(oasis_files_prefixes[k])) for k in viewkeys(oasis_files_prefixes)
    }

    concurrent_tasks = (
        Task(getattr(sys.modules[__name__], 'write_{}_file'.format(f)), args=(gul_inputs_df.copy(deep=True), gul_input_files[f],), key=f)
        for f in gul_input_files
    )
    num_ps = min(len(gul_input_files), multiprocessing.cpu_count())
    for _, _ in multithread(concurrent_tasks, pool_size=num_ps):
        pass

    return gul_input_files, gul_inputs_df, exposure_df
